{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(matrix, threshold):\n",
    "    matrix[matrix > threshold]  = 255\n",
    "    matrix[matrix <= threshold]  = 0\n",
    "    return matrix\n",
    "\n",
    "def negative(matrix):\n",
    "    matrix =  255 - matrix \n",
    "    return matrix\n",
    "\n",
    "def log_transform(matrix, c, normalize=False):\n",
    "    # Substitui valores zero por um valor pequeno para evitar logaritmo de zero\n",
    "    matrix = np.where(matrix == 0, 1e-10, matrix)\n",
    "    matrix = c * np.log(1 + matrix)\n",
    "    \n",
    "    if normalize:\n",
    "        # Calcula o valor máximo do logaritmo da imagem para normalização\n",
    "        max_log = c * np.log(1 + np.max(matrix))\n",
    "        matrix = (matrix / max_log) * 255  # Normaliza para o intervalo [0, 255]\n",
    "    \n",
    "    matrix = np.clip(matrix, 0, 255).astype(np.uint8)\n",
    "    return matrix\n",
    "\n",
    "def exponential(matrix, c, gamma):\n",
    "    matrix = matrix.astype(np.float32)\n",
    "    matrix = c * np.power(matrix, gamma)\n",
    "    matrix = np.clip(matrix, 0, 255).astype(np.uint8)\n",
    "    return matrix\n",
    "\n",
    "def equalize_histogram(frame):\n",
    "    # Equalizando o canal vermelho manualmente\n",
    "    hist, bins = np.histogram(frame.flatten(), 256, [0, 256])\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    cdf_masked = np.ma.masked_equal(cdf, 0)\n",
    "    cdf_masked = (cdf_masked - cdf_masked.min()) * 255 / (cdf_masked.max() - cdf_masked.min())\n",
    "    cdf_final = np.ma.filled(cdf_masked, 0).astype('uint8')\n",
    "    equalized = cdf_final[frame]\n",
    "\n",
    "    # Combinando os canais de cor de volta em uma imagem\n",
    "    return equalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/kaio/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "frame = cv.Mat\n",
    "frame_ = cv.Mat\n",
    "paused = False\n",
    "cap = cv.VideoCapture('../src/video.mp4')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "times = []  \n",
    "while cap.isOpened():\n",
    "    if not paused:\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "        \n",
    "        B, G, R = cv.split(frame)\n",
    "        R = threshold(R, 128)\n",
    "        G = threshold(G, 128)\n",
    "        B = threshold(B, 128)\n",
    "        frame_ = cv.merge((B, G, R))\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        times.append(processing_time)\n",
    "\n",
    "        # Calculate the average processing time\n",
    "        average_time = sum(times) / len(times)\n",
    "\n",
    "        # Put the average processing time on the frame\n",
    "        text = f\"Avg time: {average_time:.4f} sec\"\n",
    "        cv.putText(frame, text, (10, 450), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv.LINE_AA)\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    cv.imshow('frame_', frame_)\n",
    "\n",
    "    key = cv.waitKey(30)\n",
    "    if key == 27:  # Esc key to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Pause\n",
    "        paused = True\n",
    "    elif key == ord('o'):  # Continue\n",
    "        paused = False\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A imagem original, que continha uma rica variedade de tons e detalhes, é convertida em uma representação altamente simplificada. As transições suaves entre cores e as sombras são eliminadas, deixando áreas claramente definidas onde os valores de cor foram mantidos ou descartados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv.Mat\n",
    "frame_ = cv.Mat\n",
    "paused = False\n",
    "cap = cv.VideoCapture('../src/video.mp4')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "times = []  \n",
    "while cap.isOpened():\n",
    "    if not paused:\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "        \n",
    "        B, G, R = cv.split(frame)\n",
    "        R = negative(R)\n",
    "        G = negative(G)\n",
    "        B = negative(B)\n",
    "        frame_ = cv.merge((B, G, R))\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        times.append(processing_time)\n",
    "\n",
    "        # Calculate the average processing time\n",
    "        average_time = sum(times) / len(times)\n",
    "\n",
    "        # Put the average processing time on the frame\n",
    "        text = f\"Avg time: {average_time:.4f} sec\"\n",
    "        cv.putText(frame, text, (10, 450), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv.LINE_AA)\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    cv.imshow('frame_', frame_)\n",
    "\n",
    "    key = cv.waitKey(30)\n",
    "    if key == 27:  # Esc key to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Pause\n",
    "        paused = True\n",
    "    elif key == ord('o'):  # Continue\n",
    "        paused = False\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As cores vibrantes e familiares da imagem original são substituídas por versões opostas. As áreas claras da imagem se tornam escuras e vice-versa, enquanto as cores quentes se transformam em suas equivalentes frias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv.Mat\n",
    "frame_ = cv.Mat\n",
    "paused = False\n",
    "cap = cv.VideoCapture('../src/video.mp4')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "times = []\n",
    "c_values = [10, 30, 50]\n",
    "while cap.isOpened():\n",
    "    if not paused:\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "\n",
    "        B, G, R = cv.split(frame)\n",
    "        transformed_frames = []\n",
    "        for c in c_values:\n",
    "            R_transformed = log_transform(R, c, normalize=False)\n",
    "            G_transformed = log_transform(G, c, normalize=False)\n",
    "            B_transformed = log_transform(B, c, normalize=False)\n",
    "            transformed_frame = cv.merge((B_transformed, G_transformed, R_transformed))\n",
    "            transformed_frames.append(transformed_frame)\n",
    "\n",
    "        R_normalized = log_transform(R, c_values[-1], normalize=True)\n",
    "        G_normalized = log_transform(G, c_values[-1], normalize=True)\n",
    "        B_normalized = log_transform(B, c_values[-1], normalize=True)\n",
    "        normalized_frame = cv.merge((B_normalized, G_normalized, R_normalized))\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        times.append(processing_time)\n",
    "\n",
    "        average_time = sum(times) / len(times)\n",
    "\n",
    "        for i, transformed_frame in enumerate(transformed_frames):\n",
    "            cv.imshow(f'frame c={c_values[i]}', transformed_frame)\n",
    "\n",
    "        cv.imshow('Normalized frame', normalized_frame)\n",
    "        cv.imshow('frame', frame)\n",
    "\n",
    "        text = f\"Avg time: {average_time:.4f} sec\"\n",
    "        cv.putText(frame, text, (10, 450), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv.LINE_AA)\n",
    "    \n",
    "    key = cv.waitKey(30)\n",
    "    if key == 27:  # Esc key to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Pause\n",
    "        paused = True\n",
    "    elif key == ord('o'):  # Continue\n",
    "        paused = False\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O efeito visual varia conforme o valor de cc. Com valores baixos de cc, a imagem transformada se torna mais escura, com realce dos detalhes nas áreas de menor intensidade, enquanto as áreas mais claras são suavizadas. Com valores maiores de cc, a imagem aparece mais brilhante, mas com menor contraste nas áreas de alta intensidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv.Mat\n",
    "frame_ = cv.Mat\n",
    "paused = False\n",
    "cap = cv.VideoCapture('../src/video.mp4')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "times = []  \n",
    "while cap.isOpened():\n",
    "    if not paused:\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "        \n",
    "        B, G, R = cv.split(frame)\n",
    "        R = exponential(R, 0.3, 1.3)\n",
    "        G = exponential(G, 0.3, 1.3)\n",
    "        B = exponential(B, 0.3, 1.3)\n",
    "        frame_ = cv.merge((B, G, R))\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        times.append(processing_time)\n",
    "\n",
    "        # Calculate the average processing time\n",
    "        average_time = sum(times) / len(times)\n",
    "\n",
    "        # Put the average processing time on the frame\n",
    "        text = f\"Avg time: {average_time:.4f} sec\"\n",
    "        cv.putText(frame, text, (10, 450), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv.LINE_AA)\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    cv.imshow('frame_', frame_)\n",
    "\n",
    "    key = cv.waitKey(30)\n",
    "    if key == 27:  # Esc key to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Pause\n",
    "        paused = True\n",
    "    elif key == ord('o'):  # Continue\n",
    "        paused = False\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O impacto visual da transformação depende dos valores de cc e γγ. Com γ<1γ<1, a transformação realça os valores de intensidade mais baixos, tornando as áreas escuras mais brilhantes, enquanto as áreas claras são pouco afetadas, resultando em uma imagem mais clara e com mais detalhes visíveis nas sombras. Com γ>1γ>1, o efeito é oposto: a transformação comprime os valores de intensidade, tornando as áreas escuras ainda mais escuras e intensificando o brilho das áreas claras, o que pode levar à perda de detalhes nas sombras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv.Mat\n",
    "frame_ = cv.Mat\n",
    "_frame_ = cv.Mat\n",
    "paused = False\n",
    "cap = cv.VideoCapture('../src/video.mp4')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "times = []  \n",
    "while cap.isOpened():\n",
    "    if not paused:\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "        \n",
    "        B, G, R = cv.split(frame)\n",
    "        R_ = cv.equalizeHist(R)\n",
    "        R = equalize_histogram(R)\n",
    "        frame_ = cv.merge((B, G, R))\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        times.append(processing_time)\n",
    "\n",
    "        # Calculate the average processing time\n",
    "        average_time = sum(times) / len(times)\n",
    "\n",
    "        # Put the average processing time on the frame\n",
    "        text = f\"Avg time: {average_time:.4f} sec\"\n",
    "        cv.putText(frame, text, (10, 450), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv.LINE_AA)\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    cv.imshow('frame_', frame_)\n",
    "\n",
    "    key = cv.waitKey(30)\n",
    "    if key == 27:  # Esc key to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Pause\n",
    "        paused = True\n",
    "    elif key == ord('o'):  # Continue\n",
    "        paused = False\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a aplicação da equalização de histograma exclusivamente no canal vermelho, a imagem resultante ficou com uma tonalidade avermelhada. Isso ocorre porque a redistribuição dos valores de intensidade no canal vermelho faz com que ele se torne mais dominante em relação aos outros canais (verde e azul)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv.Mat\n",
    "frame_ = cv.Mat\n",
    "paused = False\n",
    "cap = cv.VideoCapture('../src/video.mp4')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "times = []  \n",
    "while cap.isOpened():\n",
    "    if not paused:\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can’t receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        frame_ = threshold(frame, np.mean(frame))\n",
    "\n",
    "        kernel = np.ones((9, 9), np.uint8)\n",
    "\n",
    "        frame_ = cv.erode(frame_, kernel, iterations=1)\n",
    "        frame_ = cv.dilate(frame_, kernel, iterations=1)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        times.append(processing_time)\n",
    "\n",
    "        # Calculate the average processing time\n",
    "        average_time = sum(times) / len(times)\n",
    "\n",
    "        # Put the average processing time on the frame\n",
    "        text = f\"Avg time: {average_time:.4f} sec\"\n",
    "        cv.putText(frame, text, (10, 450), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv.LINE_AA)\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    cv.imshow('frame_', frame_)\n",
    "\n",
    "    key = cv.waitKey(30)\n",
    "    if key == 27:  # Esc key to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Pause\n",
    "        paused = True\n",
    "    elif key == ord('o'):  # Continue\n",
    "        paused = False\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O vídeo transformado apresenta uma redução significativa nos detalhes, com contornos e formas simplificados. A aplicação de erosão e dilatação destaca ainda mais as bordas dos objetos e pode criar efeitos de \"desgaste\" ou \"inchaço\" nas formas. O resultado é um vídeo que enfatiza as formas e estruturas principais, perdendo as gradações suaves e detalhes presentes no vídeo original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
